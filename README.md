# ğŸ¯ JobInsight Data Pipeline

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![Airflow](https://img.shields.io/badge/Airflow-2.7-green.svg)](https://airflow.apache.org)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://docker.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **End-to-end Data Pipeline** crawling IT jobs from TopCV.vn â†’ **Star Schema DWH** â†’ Analytics dashboards

**Highlights**:
- ğŸ•·ï¸ Production-grade web scraping with anti-detection
- ğŸ›ï¸ Kimball dimensional modeling (SCD Type 2, Periodic Snapshot)
- ğŸ›¡ï¸ Multi-layer quality validation & automated monitoring
- ğŸ“Š Modern data stack (Airflow, PostgreSQL, DuckDB, MinIO)

---

## ğŸ“‘ Table of Contents

- ğŸ›ï¸ [Architecture](#-architecture)
- âš¡ [Key Features](#-key-features)
- ğŸš€ [Quick Start](#-quick-start)
- ğŸŒŸ [Star Schema](#-star-schema)
- ğŸ“š [Documentation](#-documentation)
- ğŸ› ï¸ [Tech Stack](#-tech-stack)
- ğŸ’¡ [Lessons Learned](#-lessons-learned)

---

## ğŸ›ï¸ Architecture

![Architecture Diagram](images/architecture.png)

### System Components

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Orchestration** | Apache Airflow 2.7 | DAG scheduling, workflow management |
| **OLTP Database** | PostgreSQL 13 | Raw & staging data storage |
| **OLAP Database** | DuckDB | Data Warehouse (Star Schema) |
| **Object Storage** | MinIO | HTML backups, archives, DWH files |
| **Web Scraping** | Playwright | Anti-detection crawler |
| **Monitoring** | Grafana | Pipeline metrics & data quality |
| **Analytics** | Apache Superset | Business intelligence dashboards |
| **Infrastructure** | Docker Compose | Multi-container environment |

---

## âš¡ Key Features

### ğŸ•·ï¸ Production-Grade Web Scraping
- Anti-bot detection (random UA, human-like behavior, circuit breaker)
- Retry logic with exponential backoff
- Multi-selector fallback for resilient parsing

### ğŸ›ï¸ Kimball Dimensional Modeling  
- Pure Periodic Snapshot with carry-forward logic
- SCD Type 2 for tracking historical changes
- Bridge table for many-to-many relationships

### ğŸ›¡ï¸ Multi-Layer Data Quality
- 3-layer validation (Crawl â†’ Business Rules â†’ Staging)
- Quality gates with hard fail (â‰¥90% valid rate)
- Automated monitoring & alerts

> ï¿½ **Details**: [ARCHITECTURE](docs/ARCHITECTURE.md) | [Data Quality Rules](docs/governance/data_quality_rules.md)

---

## ğŸ› ï¸ Tech Stack

### Data Engineering
- **Python 3.9+** - Core language
- **Apache Airflow 2.7** - Workflow orchestration
- **Playwright** - Headless browser automation
- **Pandas + PyArrow** - Data transformation & Parquet I/O

### Databases & Storage
- **PostgreSQL 13** - OLTP (raw_jobs, staging_jobs, monitoring)
- **DuckDB** - OLAP warehouse with Star Schema
- **MinIO** - S3-compatible object storage

### Visualization & Monitoring
- **Grafana 10.2** - Pipeline monitoring
- **Apache Superset 3.0** - Business intelligence
- **Docker Compose** - Multi-container orchestration

---

## ğŸš€ Quick Start

### Prerequisites
- **Docker** & **Docker Compose** (v4.22+)
- **RAM**: 8GB+ recommended
- **Ports**: 8080, 8088, 3000, 9000, 9001, 5434

### Installation

```bash
# 1. Clone repository
git clone https://github.com/Trantuan24/JobInsight_Data_Pipeline_v2.git
cd JobInsight_Data_Pipeline_v2

# 2. Create environment file
cp .env.example .env

# 3. Start all services (first run: 5-10 minutes)
docker compose up -d

# 4. Check service health
docker compose ps
```

### ğŸŒ Access Services

| Service | URL | Login |
|---------|-----|-------|
| **Airflow** - Pipeline Orchestration | [localhost:8080](http://localhost:8080) | `admin` / `admin` |
| **Grafana** - Pipeline Monitoring | [localhost:3000](http://localhost:3000) | `admin` / `admin` |
| **Superset** - Business Analytics | [localhost:8088](http://localhost:8088) | `admin` / `admin` |
| **MinIO** - Object Storage Console | [localhost:9001](http://localhost:9001) | `minioadmin` / `minioadmin` |

### â–¶ï¸ Run Your First Pipeline

```bash
# Trigger main pipeline (or wait until 6:00 AM daily)
docker exec jobinsight-airflow-webserver-1 \
  airflow dags trigger jobinsight_pipeline

# Check status
docker exec jobinsight-airflow-webserver-1 \
  airflow dags list-runs -d jobinsight_pipeline

# View real-time logs
docker compose logs -f airflow-scheduler
```

**Expected flow**: Crawl (2min) â†’ Parse â†’ Validate â†’ Staging â†’ DWH â†’ Done! âœ…

> ğŸ’¡ **First run**: Pipeline DAG (6AM) â†’ DWH DAG (7AM). Check Grafana for metrics!

---

## ğŸ”„ Data Flow

```
TopCV.vn â†’ Playwright Crawler
    â†“
PostgreSQL (raw â†’ staging)  
    â†“
DuckDB Star Schema (MinIO)
    â†“
Grafana (Monitoring) + Superset (Analytics)
```

**4 Daily DAGs**: Maintenance (3AM) â†’ Pipeline (6AM) â†’ DWH (7AM) â†’ Archive (Sun 2AM)

> ğŸ“– **Details**: [ARCHITECTURE](docs/ARCHITECTURE.md#data-flow) | [DAG Documentation](docs/ARCHITECTURE.md#orchestration)

---

## ğŸŒŸ Star Schema

![Star Schema](images/jobinsight_star_schema_diagram.png)

**Fact**: FactJobPostingDaily (Pure Periodic Snapshot, grain: 1 job Ã— 1 day)  
**Dimensions**: DimJob (SCD2) â€¢ DimCompany (SCD2) â€¢ DimLocation â€¢ DimDate (role-playing)  
**Bridge**: FactJobLocationBridge (many-to-many: jobs Ã— locations)

> ğŸ“– **Details**: [Bus Matrix](docs/governance/bus_matrix.md) | [Data Contracts](docs/data_contracts/) | [DBML Schema](docs/dwh_schema.dbml)



---

## ğŸ“š Documentation

### Core Documentation
- ğŸ“– [Architecture](docs/ARCHITECTURE.md) - System design, carry-forward logic, data flow
- ğŸ› ï¸ [Development Guide](docs/DEVELOPMENT.md) - Setup, workflow, code structure
- ğŸš¨ [Troubleshooting](docs/TROUBLESHOOTING.md) - Common issues & solutions

### Data Governance
- ğŸ“‹ [Data Contracts](docs/data_contracts/) - YAML schema definitions (ODCS v3.1)
- ğŸ¯ [Bus Matrix](docs/governance/bus_matrix.md) - Dimensional relationships
- âœ… [Data Quality Rules](docs/governance/data_quality_rules.md) - Validation thresholds
- ğŸ—„ï¸ [Retention Policies](docs/governance/retention_policies.md) - Data lifecycle management

### Infrastructure
- ğŸª£ [MinIO Guide](docs/infrastructure/minio_guide.md) - Object storage setup
- ğŸ“Š [Grafana & Superset](docs/infrastructure/grafana_superset_guide.md) - Visualization tools

---

## ğŸ’¡ Lessons Learned

### âœ… What Went Well
- **Kimball methodology** - Star schema made analytics simple & fast
- **DuckDB on MinIO** - $0 OLAP warehouse with Parquet exports
- **Quality gates** - Multi-layer validation catches >95% issues
- **Docker Compose** - Easy local dev & reproducible builds

### ğŸ”¥ Key Challenges
- **Multi-location jobs** â†’ Solved with Bridge table
- **SCD Type 2** â†’ Unique index on `(bk WHERE is_current = TRUE)`
- **Anti-detection scraping** â†’ Circuit breaker prevents IP bans
- **DuckDB + Superset** â†’ Remove `:ro` from volume mount

### ğŸš€ Future Enhancements
- More data sources (LinkedIn, Indeed)
- Real-time streaming (Kafka)
- ML models (salary prediction)
- Cloud deployment (K8s + Terraform)

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

**Guidelines**:
- Follow PEP 8 for Python code
- Add tests for new features
- Update documentation
- Run `black` and `flake8` before committing

---

## ğŸ“§ Contact

**Author**: [Duy Tuáº¥n]

- ğŸ“§ Email: duytuan2412k4@gmail.com
- ğŸ™ GitHub: [@Trantuan24](https://github.com/Trantuan24)

Feel free to reach out if you have questions or want to discuss data engineering!

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Kimball Group** - Dimensional modeling methodology
- **Apache Airflow** - Workflow orchestration
- **DuckDB Team** - In-process OLAP database
- **TopCV.vn** - Job listing data source

---

## â­ Show Your Support

If you found this project helpful, please give it a **star** â­!

It helps others discover the project and motivates me to keep improving it. Thank you! ğŸ™

---
